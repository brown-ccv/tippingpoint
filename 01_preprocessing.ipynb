{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "Here we describe how we read in data, clean it up and provide more machine-readable column names, and separate out some columns for additional analyses.\n",
    "\n",
    "Data is stored in:\n",
    " * data\n",
    " \n",
    "It consists of 3 files that have been converted from Excel (how they were provided) to CSVs in Excel:\n",
    " * TP_DV_File.csv\n",
    " * TP_Graph_Characteristics.csv\n",
    " * TP_Subject_file.csv\n",
    " \n",
    "Below is brief descriptions of them (more extensive descriptions are in the Word doc)\n",
    "\n",
    "### TP_DV_File.csv\n",
    "\n",
    "A table containing the subject, the graph and point combination, and whether it was marked as a tipping point or not.\n",
    "\n",
    "### TP_Graph_Characteristics.csv\n",
    "\n",
    "These are about characteristics of the graphs. To code the characteristics 5 different reviewers coded a characteristic, if there were differences majority opinion was used if more than 3 reviewers coded the graph as the same (i.e. greater than 60% overall). Otherwise the characteristics was left blank.\n",
    "\n",
    "### TP_Subject_file.csv\n",
    "\n",
    "A table about the subjects, many variables here some of which are likely correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/DataFrames/AR9oZ.ji for DataFrames [a93c6f00-e57d-5684-b7b6-d8193f3e46c0]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module Compat with build ID 338149074950152 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/CategoricalArrays/RHXoP.ji for CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module Compat with build ID 338149074950152 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/Tables/Z804B.ji for Tables [bd369af6-aec1-5ad0-b16a-f7cc5008161c]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/CSV/HHBkp.ji for CSV [336ed68f-0bac-5ca0-87d4-7b16caf5d00b]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module CategoricalArrays with build ID 69420699387314 is missing from the cache.\n",
      "│ This may mean CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/GLM/6OREG.ji for GLM [38e38edf-8417-5370-95a0-9cbb8c7f171a]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module CategoricalArrays with build ID 69420699387314 is missing from the cache.\n",
      "│ This may mean CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Warning: Module CategoricalArrays with build ID 69420699387314 is missing from the cache.\n",
      "│ This may mean CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Precompiling StatsModels [3eaba693-59b7-5ba5-a881-562e759f1c8d]\n",
      "└ @ Base loading.jl:1186\n",
      "┌ Warning: Module CategoricalArrays with build ID 69420699387314 is missing from the cache.\n",
      "│ This may mean CategoricalArrays [324d7699-5711-5eae-9e2f-1d82baa6b597] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/Gadfly/DvECm.ji for Gadfly [c91e804a-d5a3-530f-b6f0-dfbca275c004]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Module Compat with build ID 338149074950152 is missing from the cache.\n",
      "│ This may mean Compat [34da2185-b29b-5c13-b0c7-acf172513d20] does not support precompilation but is imported by a module that does.\n",
      "└ @ Base loading.jl:947\n",
      "┌ Info: Recompiling stale cache file /Users/aguang/.julia/compiled/v1.1/Compose/sbiEw.ji for Compose [a81c6b42-2e10-5240-aca2-a61377ecd94b]\n",
      "└ @ Base loading.jl:1184\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using GLM\n",
    "using Gadfly\n",
    "using Statistics\n",
    "using NamedArrays\n",
    "\n",
    "DATA=\"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each CSV file we wrote a function `clean_x` to read in the file and then rename the columns. Each function has roughly the same two lines: `CSV.File` reads in the file, the `|> DataFrame!` pipes it and converts it into a dataframe, and then `names!` sets the column names as something both short and human identifiable. A quick check of the size of `df_dv` reveals that it has 5696 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5696, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean_dv(filepath)\n",
    "    df = CSV.File(filepath,normalizenames=true) |> DataFrame!\n",
    "    names!(df, [:subj, :graphid, :tp])\n",
    "end\n",
    "\n",
    "df_dv = clean_dv(joinpath(DATA,\"TP_DV_file.csv\"))\n",
    "size(df_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DV we additionally split out the `graphid` column into `q` (specific graph) and `pt` (specific point on the graph). We add these to the dataframe `df_dv` as new columns. A quick check with `size` confirms that we now have 5 columns in `df_dv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5696, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding some additional columns for category and pt\n",
    "df_dv.q = [split(s)[1] for s in df_dv.graphid]\n",
    "df_dv.pt = [split(s)[2] for s in df_dv.graphid]\n",
    "size(df_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the preprocessing goes similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean_gc(filepath)\n",
    "    df = CSV.File(filepath,normalizenames=true) |> DataFrame!\n",
    "    names!(df, [:graphid, :risingBefore, :cannotSeeAfter, :downOverall, :bellOverall, :complexOverall])\n",
    "end\n",
    "\n",
    "df_gc = clean_gc(joinpath(DATA,\"TP_Graph_Characteristics.csv\"))\n",
    "size(df_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean_subject(filepath)\n",
    "    df = CSV.File(filepath,normalizenames=true) |> DataFrame!\n",
    "    names!(df, [:subj, :uniBrown, :expExec, :tpChange, :tpRate, :tpDir, :tpNoReturn,\n",
    "            :tellMgr, :impChange, :impRise, :impFall, :impPeriodic, :numOtherTP,\n",
    "            :liwcPosemo, :liwcNegemo, :liwcCause, :liwcFocusPre, :liwcFocusFut,\n",
    "            :liwcRelativ, :liwcTime])\n",
    "end\n",
    "\n",
    "df_subject = clean_subject(joinpath(DATA,\"TP_Subject_file.csv\"))\n",
    "size(df_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combine all of the dataframes together into a full dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>subj</th><th>graphid</th><th>tp</th><th>q</th><th>pt</th><th>risingBefore</th><th>cannotSeeAfter</th><th>downOverall</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Int64⍰</th><th>SubStrin…</th><th>SubStrin…</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>6 rows × 29 columns (omitted printing of 21 columns)</p><tr><th>1</th><td>1</td><td>Q2 A</td><td>0</td><td>Q2</td><td>A</td><td>1</td><td>0</td><td>0</td></tr><tr><th>2</th><td>1</td><td>Q2 B</td><td>0</td><td>Q2</td><td>B</td><td>1</td><td>0</td><td>0</td></tr><tr><th>3</th><td>1</td><td>Q2 C</td><td>0</td><td>Q2</td><td>C</td><td>1</td><td>1</td><td>0</td></tr><tr><th>4</th><td>1</td><td>Q3 A</td><td>0</td><td>Q3</td><td>A</td><td>1</td><td>0</td><td>1</td></tr><tr><th>5</th><td>1</td><td>Q3 B</td><td>0</td><td>Q3</td><td>B</td><td>0</td><td>0</td><td>1</td></tr><tr><th>6</th><td>1</td><td>Q3 C</td><td>0</td><td>Q3</td><td>C</td><td>0</td><td>0</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& subj & graphid & tp & q & pt & risingBefore & cannotSeeAfter & downOverall & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Int64⍰ & SubStrin… & SubStrin… & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & Q2 A & 0 & Q2 & A & 1 & 0 & 0 & $\\dots$ \\\\\n",
       "\t2 & 1 & Q2 B & 0 & Q2 & B & 1 & 0 & 0 & $\\dots$ \\\\\n",
       "\t3 & 1 & Q2 C & 0 & Q2 & C & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t4 & 1 & Q3 A & 0 & Q3 & A & 1 & 0 & 1 & $\\dots$ \\\\\n",
       "\t5 & 1 & Q3 B & 0 & Q3 & B & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t6 & 1 & Q3 C & 0 & Q3 & C & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×29 DataFrame. Omitted printing of 23 columns\n",
       "│ Row │ subj  │ graphid │ tp     │ q         │ pt        │ risingBefore │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mString\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mSubStrin…\u001b[39m │ \u001b[90mSubStrin…\u001b[39m │ \u001b[90mInt64\u001b[39m        │\n",
       "├─────┼───────┼─────────┼────────┼───────────┼───────────┼──────────────┤\n",
       "│ 1   │ 1     │ Q2 A    │ 0      │ Q2        │ A         │ 1            │\n",
       "│ 2   │ 1     │ Q2 B    │ 0      │ Q2        │ B         │ 1            │\n",
       "│ 3   │ 1     │ Q2 C    │ 0      │ Q2        │ C         │ 1            │\n",
       "│ 4   │ 1     │ Q3 A    │ 0      │ Q3        │ A         │ 1            │\n",
       "│ 5   │ 1     │ Q3 B    │ 0      │ Q3        │ B         │ 0            │\n",
       "│ 6   │ 1     │ Q3 C    │ 0      │ Q3        │ C         │ 0            │"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `T` is deprecated, use `nonmissingtype` instead.\n",
      "│   caller = compacttype(::Type, ::Int64) at show.jl:39\n",
      "└ @ DataFrames /Users/aguang/.julia/packages/DataFrames/Iyo5L/src/abstractdataframe/show.jl:39\n"
     ]
    }
   ],
   "source": [
    "full_df = join(df_dv, df_gc, on= :graphid)\n",
    "full_df = join(full_df, df_subject, on = :subj)\n",
    "first(full_df, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we save the dataframes for other notebooks to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/aguang/CORE/tippingpoint/tippingpoint/data/full_df.dat\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(joinpath(DATA,\"df_dv.dat\"), df_dv)\n",
    "CSV.write(joinpath(DATA,\"df_gc.dat\"), df_gc)\n",
    "CSV.write(joinpath(DATA,\"df_subject.dat\"), df_subject)\n",
    "CSV.write(joinpath(DATA,\"full_df.dat\"), full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses\n",
    "\n",
    "The next part of the notebook to run is `02_descriptive_logistic`. We will go over the hypotheses again there. But briefly, here are the hypotheses we were looking at.\n",
    "\n",
    "Our broad hypotheses are that: tipping points cannot be predicted, that bias and experience make one less likely to declare a tipping point, and that collective decision making makes a single individual less likely to declare a tipping point.\n",
    "\n",
    "Specifically from our independent variables, we wanted to test the following hypotheses:\n",
    "\n",
    " 1. If cannot see what follows point of interest, less likely to declare a TP\n",
    " 2. If graph is rising before point of interest, more likely to declare a TP\n",
    " 3. If subject is more experienced, less likely to declare a TP\n",
    " 4. If more noise in overall graph, less likely to declare a TP\n",
    " 5. If view a sustained change as important, less likely to declare a TP\n",
    " 6. If likely to tell manager, more likely to declare a TP\n",
    " 7. If see \"other\" TPs, more likely to declare a TP\n",
    " 8. If view a decline as important, more likely to declare a TP if point has a decline\n",
    " 9. Emotions drive TP observations\n",
    " 10. If group is small, more likely to declare a TP\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
