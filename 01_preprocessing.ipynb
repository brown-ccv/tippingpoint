{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "Here we describe how we read in data, clean it up and provide more machine-readable column names, and separate out some columns for additional analyses.\n",
    "\n",
    "Data is stored in:\n",
    " * /Users/aguang/CORE/tippingpoint/data\n",
    " \n",
    "It consists of 3 files that have been converted from Excel (how they were provided) to CSVs in Excel:\n",
    " * TP_DV_File.csv\n",
    " * TP_Graph_Characteristics.csv\n",
    " * TP_Subject_file.csv\n",
    " \n",
    "Below is brief descriptions of them (more extensive descriptions are in the Word doc)\n",
    "\n",
    "### TP_DV_File.csv\n",
    "\n",
    "A table containing the subject, the graph and point combination, and whether it was marked as a tipping point or not.\n",
    "\n",
    "### TP_Graph_Characteristics.csv\n",
    "\n",
    "These are about characteristics of the graphs. To code the characteristics 5 different reviewers coded a characteristic, if there were differences majority opinion was used if more than 3 reviewers coded the graph as the same (i.e. greater than 60% overall). Otherwise the characteristics was left blank.\n",
    "\n",
    "### TP_Subject_file.csv\n",
    "\n",
    "A table about the subjects, many variables here some of which are likely correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/aguang/CORE/tippingpoint/tippingpoint/data\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "using GLM\n",
    "using Gadfly\n",
    "using Statistics\n",
    "using NamedArrays\n",
    "\n",
    "DATA=\"/Users/aguang/CORE/tippingpoint/tippingpoint/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each CSV file we wrote a function `clean_x` to read in the file and then rename the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5696, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean_dv(filepath)\n",
    "    df = CSV.File(filepath,normalizenames=true) |> DataFrame!\n",
    "    names!(df, [:subj, :graphid, :tp])\n",
    "end\n",
    "\n",
    "df_dv = clean_dv(joinpath(DATA,\"TP_DV_file.csv\"))\n",
    "size(df_dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DV we additionally split out the `graphid` column into `q` (specific graph) and `pt` (specific point on the graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5696, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding some additional columns for category and pt\n",
    "df_dv.q = [split(s)[1] for s in df_dv.graphid]\n",
    "df_dv.pt = [split(s)[2] for s in df_dv.graphid]\n",
    "size(df_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean_gc(filepath)\n",
    "    df = CSV.File(filepath,normalizenames=true) |> DataFrame!\n",
    "    names!(df, [:graphid, :risingBefore, :cannotSeeAfter, :downOverall, :bellOverall, :complexOverall])\n",
    "end\n",
    "\n",
    "df_gc = clean_gc(joinpath(DATA,\"TP_Graph_Characteristics.csv\"))\n",
    "size(df_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function clean_subject(filepath)\n",
    "    df = CSV.File(filepath,normalizenames=true) |> DataFrame!\n",
    "    names!(df, [:subj, :uniBrown, :expExec, :tpChange, :tpRate, :tpDir, :tpNoReturn,\n",
    "            :tellMgr, :impChange, :impRise, :impFall, :impPeriodic, :numOtherTP,\n",
    "            :liwcPosemo, :liwcNegemo, :liwcCause, :liwcFocusPre, :liwcFocusFut,\n",
    "            :liwcRelativ, :liwcTime])\n",
    "end\n",
    "\n",
    "df_subject = clean_subject(joinpath(DATA,\"TP_Subject_file.csv\"))\n",
    "size(df_subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combine all of the dataframes together into a full dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>subj</th><th>graphid</th><th>tp</th><th>q</th><th>pt</th><th>risingBefore</th><th>cannotSeeAfter</th><th>downOverall</th></tr><tr><th></th><th>Int64</th><th>String</th><th>Int64⍰</th><th>SubStrin…</th><th>SubStrin…</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>6 rows × 29 columns (omitted printing of 21 columns)</p><tr><th>1</th><td>1</td><td>Q2 A</td><td>0</td><td>Q2</td><td>A</td><td>1</td><td>0</td><td>0</td></tr><tr><th>2</th><td>1</td><td>Q2 B</td><td>0</td><td>Q2</td><td>B</td><td>1</td><td>0</td><td>0</td></tr><tr><th>3</th><td>1</td><td>Q2 C</td><td>0</td><td>Q2</td><td>C</td><td>1</td><td>1</td><td>0</td></tr><tr><th>4</th><td>1</td><td>Q3 A</td><td>0</td><td>Q3</td><td>A</td><td>1</td><td>0</td><td>1</td></tr><tr><th>5</th><td>1</td><td>Q3 B</td><td>0</td><td>Q3</td><td>B</td><td>0</td><td>0</td><td>1</td></tr><tr><th>6</th><td>1</td><td>Q3 C</td><td>0</td><td>Q3</td><td>C</td><td>0</td><td>0</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& subj & graphid & tp & q & pt & risingBefore & cannotSeeAfter & downOverall & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String & Int64⍰ & SubStrin… & SubStrin… & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & Q2 A & 0 & Q2 & A & 1 & 0 & 0 & $\\dots$ \\\\\n",
       "\t2 & 1 & Q2 B & 0 & Q2 & B & 1 & 0 & 0 & $\\dots$ \\\\\n",
       "\t3 & 1 & Q2 C & 0 & Q2 & C & 1 & 1 & 0 & $\\dots$ \\\\\n",
       "\t4 & 1 & Q3 A & 0 & Q3 & A & 1 & 0 & 1 & $\\dots$ \\\\\n",
       "\t5 & 1 & Q3 B & 0 & Q3 & B & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\t6 & 1 & Q3 C & 0 & Q3 & C & 0 & 0 & 1 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×29 DataFrame. Omitted printing of 23 columns\n",
       "│ Row │ subj  │ graphid │ tp     │ q         │ pt        │ risingBefore │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mString\u001b[39m  │ \u001b[90mInt64⍰\u001b[39m │ \u001b[90mSubStrin…\u001b[39m │ \u001b[90mSubStrin…\u001b[39m │ \u001b[90mInt64\u001b[39m        │\n",
       "├─────┼───────┼─────────┼────────┼───────────┼───────────┼──────────────┤\n",
       "│ 1   │ 1     │ Q2 A    │ 0      │ Q2        │ A         │ 1            │\n",
       "│ 2   │ 1     │ Q2 B    │ 0      │ Q2        │ B         │ 1            │\n",
       "│ 3   │ 1     │ Q2 C    │ 0      │ Q2        │ C         │ 1            │\n",
       "│ 4   │ 1     │ Q3 A    │ 0      │ Q3        │ A         │ 1            │\n",
       "│ 5   │ 1     │ Q3 B    │ 0      │ Q3        │ B         │ 0            │\n",
       "│ 6   │ 1     │ Q3 C    │ 0      │ Q3        │ C         │ 0            │"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `T` is deprecated, use `nonmissingtype` instead.\n",
      "│   caller = compacttype(::Type, ::Int64) at show.jl:39\n",
      "└ @ DataFrames /Users/aguang/.julia/packages/DataFrames/Iyo5L/src/abstractdataframe/show.jl:39\n"
     ]
    }
   ],
   "source": [
    "full_df = join(df_dv, df_gc, on= :graphid)\n",
    "full_df = join(full_df, df_subject, on = :subj)\n",
    "first(full_df, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we save the dataframes for other notebooks to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/aguang/CORE/tippingpoint/tippingpoint/data/full_df.dat\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(joinpath(DATA,\"df_dv.dat\"), df_dv)\n",
    "CSV.write(joinpath(DATA,\"df_gc.dat\"), df_gc)\n",
    "CSV.write(joinpath(DATA,\"df_subject.dat\"), df_subject)\n",
    "CSV.write(joinpath(DATA,\"full_df.dat\"), full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
